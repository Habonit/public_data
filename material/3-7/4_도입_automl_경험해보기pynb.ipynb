{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# AutoML 도입 - AutoGluon 경험해보기\n\n이 노트북에서는 **AutoGluon**을 사용하여 AutoML(자동 머신러닝)을 경험해봅니다.\n\n## 학습 목표\n1. AutoGluon 라이브러리 설치 및 기본 사용법 익히기\n2. TabularPredictor를 활용한 테이블 데이터 예측\n3. Multi-target Regression (다중 타깃 회귀) 실습\n4. AutoML의 장점과 한계 이해하기\n\n## AutoGluon 특징\n- **자동 피처 엔지니어링**: 범주형 변수 자동 인코딩\n- **다양한 모델 앙상블**: LightGBM, XGBoost, Neural Network 등\n- **Presets**: `best_quality`, `medium_quality_faster_train` 등 품질/속도 선택\n\n## 사용 데이터\n- 자율주행 관련 데이터셋 (Y_01 ~ Y_14 타깃)\n- X features: 56개\n- 각 타깃별 최소/최대 spec 정보 활용\n\n## 실습 환경\n- Google Colab\n- Python 3.x",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "r-GOErt1Wq9R",
    "outputId": "76647beb-044b-4652-913a-8fdb5550a804"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  fonts-nanum\n",
      "0 upgraded, 1 newly installed, 0 to remove and 46 not upgraded.\n",
      "Need to get 10.3 MB of archives.\n",
      "After this operation, 34.1 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
      "Fetched 10.3 MB in 2s (4,626 kB/s)\n",
      "Selecting previously unselected package fonts-nanum.\n",
      "(Reading database ... 121713 files and directories currently installed.)\n",
      "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
      "Unpacking fonts-nanum (20200506-1) ...\n",
      "Setting up fonts-nanum (20200506-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
      "matplotlibrc 경로: /usr/local/lib/python3.12/dist-packages/matplotlib/mpl-data/matplotlibrc\n",
      "matplotlib 기본 폰트 파일: /usr/local/lib/python3.12/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf\n",
      "기본 폰트를 나눔고딕으로 교체 완료\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 0. 한글 출력을 위한 기초 셀\n",
    "#    (코랩에서 한 번만 실행하면 이후 그래프에 한글이 깨지지 않도록 설정)\n",
    "#    참조: https://conding-note.tistory.com/335\n",
    "# ==========================================\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install -y fonts-nanum\n",
    "\n",
    "import matplotlib as mpl\n",
    "print(\"matplotlibrc 경로:\", mpl.matplotlib_fname())\n",
    "\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "\n",
    "# matplotlib 설정 파일(matplotlibrc)의 경로에서 루트 디렉토리만 추출\n",
    "# 예) /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/matplotlibrc\n",
    "#  → /usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/\n",
    "root = mpl.matplotlib_fname().replace(\"matplotlibrc\", \"\")\n",
    "\n",
    "# matplotlib 기본 폰트 파일(DejaVuSans.ttf)이 위치한 경로\n",
    "target_font = root + \"fonts/ttf/DejaVuSans.ttf\"\n",
    "print(\"matplotlib 기본 폰트 파일:\", target_font)\n",
    "\n",
    "# 나눔고딕 폰트 경로 (Ubuntu/Colab에서 설치되는 경로)\n",
    "nanum_font = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "\n",
    "# shutil.copyfile:\n",
    "# - 파일을 다른 경로로 복사하는 함수\n",
    "# - 여기서는 DejaVuSans.ttf 파일을 나눔고딕으로 교체하여\n",
    "#   matplotlib의 기본 폰트를 나눔고딕으로 바꿉니다.\n",
    "shutil.copyfile(nanum_font, target_font)\n",
    "print(\"기본 폰트를 나눔고딕으로 교체 완료\")\n",
    "\n",
    "# matplotlib 캐시 삭제\n",
    "# - 캐시에 이전 폰트 정보가 남아 있으면 새 폰트가 바로 적용되지 않을 수 있어\n",
    "#   캐시를 삭제하여 강제로 다시 로딩하도록 합니다.\n",
    "!rm -rf ~/.cache/matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# seaborn 스타일을 'whitegrid'로 지정 (흰 배경 + 그리드)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 테스트 플롯 (한글 출력 확인)\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title(\"한글 폰트 정상 출력 확인\")\n",
    "plt.xlabel(\"가로축\")\n",
    "plt.ylabel(\"세로축\")\n",
    "plt.plot([1,2,3], [1,4,2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 0. 환경 설정 및 기본 로드\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# 1) gdown 설치 (한 번만 실행)\n",
    "!pip install -q gdown\n",
    "\n",
    "# 2) 구글 드라이브에서 데이터 zip 파일 다운로드\n",
    "#   - id 뒤에 있는 값이 링크의 파일 ID입니다.\n",
    "#   - 필요하면 파일 이름(autonomous_driving.zip)만 바꿔서 쓰시면 됩니다.\n",
    "\n",
    "FILE_ID = \"10Hpa4YM0KX_Ig0W9w7DbTdq62nF2UThA\"\n",
    "OUTPUT_ZIP = \"autonomous_driving.zip\"\n",
    "\n",
    "!gdown --id {FILE_ID} -O {OUTPUT_ZIP}\n",
    "\n",
    "# 3) 압축 해제\n",
    "#   - autonomous_driving 폴더 아래에 내용을 풀어놓습니다.\n",
    "#   - 압축이 zip이 아니라면 확장자에 맞게 unzip 대신 다른 명령을 쓰셔야 합니다.\n",
    "\n",
    "!mkdir -p autonomous_driving\n",
    "!unzip -q {OUTPUT_ZIP} -d autonomous_driving\n",
    "\n",
    "# 잘 풀렸는지 확인\n",
    "!ls -R autonomous_driving\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8sPzGZxWt49",
    "outputId": "56584214-6367-4344-9371-db2c8dbb49cf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=10Hpa4YM0KX_Ig0W9w7DbTdq62nF2UThA\n",
      "To: /content/autonomous_driving.zip\n",
      "100% 10.0M/10.0M [00:00<00:00, 73.6MB/s]\n",
      "autonomous_driving:\n",
      "meta  sample_submission.csv  test.csv  train.csv\n",
      "\n",
      "autonomous_driving/meta:\n",
      "x_feature_info.csv  y_feature_info.csv\ty_feature_spec_info.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 1. AutoGluon 설치\n",
    "# ============================================================\n",
    "\n",
    "!pip install -q autogluon.tabular\n",
    "\n",
    "from autogluon.tabular import TabularPredictor"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qi95Wx6xW-kV",
    "outputId": "32c4e43d-4a06-4bee-91b9-861c72336255"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/487.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.3/487.3 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 2. 데이터 로드\n",
    "# ============================================================\n",
    "\n",
    "BASE_PATH = \"/content/autonomous_driving\"\n",
    "\n",
    "train = pd.read_csv(f\"{BASE_PATH}/train.csv\")\n",
    "test = pd.read_csv(f\"{BASE_PATH}/test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{BASE_PATH}/sample_submission.csv\")\n",
    "\n",
    "y_spec = pd.read_csv(f\"{BASE_PATH}/meta/y_feature_spec_info.csv\")\n",
    "\n",
    "# X, Y 지정\n",
    "X_cols = [c for c in train.columns if c.startswith(\"X_\")]\n",
    "target_cols = [c for c in sample_submission.columns if c != \"ID\"]\n",
    "\n",
    "# y_spec 최소·최대\n",
    "spec_min = dict(zip(y_spec[\"Feature\"], y_spec[\"최소\"]))\n",
    "spec_max = dict(zip(y_spec[\"Feature\"], y_spec[\"최대\"]))"
   ],
   "metadata": {
    "id": "UVfn4idzZeji"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 3. 기본 설정 (피처 / 타깃 정의)\n",
    "# ============================================================\n",
    "\n",
    "# X feature 컬럼: X_로 시작하는 컬럼 전부\n",
    "X_cols = [c for c in train.columns if c.startswith(\"X_\")]\n",
    "\n",
    "# 타깃 컬럼: sample_submission의 ID를 제외한 나머지 (Y_01 ~ Y_14)\n",
    "target_cols = [c for c in sample_submission.columns if c != \"ID\"]\n",
    "\n",
    "print(\"X_cols (개수):\", len(X_cols))\n",
    "print(\"target_cols:\", target_cols)\n",
    "\n",
    "# y_spec에서 각 타깃별 최소/최대 dict 생성 (클리핑용)\n",
    "spec_min = dict(zip(y_spec[\"Feature\"], y_spec[\"최소\"]))\n",
    "spec_max = dict(zip(y_spec[\"Feature\"], y_spec[\"최대\"]))\n",
    "\n",
    "print(\"예시 spec_min:\", {k: spec_min[k] for k in target_cols[:3]})\n",
    "print(\"예시 spec_max:\", {k: spec_max[k] for k in target_cols[:3]})"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJtZwUgsZoeN",
    "outputId": "00073ac7-e4d5-429c-810a-f21d95469604"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_cols (개수): 56\n",
      "target_cols: ['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', 'Y_06', 'Y_07', 'Y_08', 'Y_09', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14']\n",
      "예시 spec_min: {'Y_01': 0.2, 'Y_02': 0.2, 'Y_03': 0.2}\n",
      "예시 spec_max: {'Y_01': 2.0, 'Y_02': 2.1, 'Y_03': 2.1}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 3. Full AutoML: AutoGluon Best Quality + Ensemble/Stacking\n",
    "# ============================================================\n",
    "\n",
    "MODEL_ROOT = f\"{BASE_PATH}/Autogluon_Full\"\n",
    "\n",
    "# 결과 저장\n",
    "test_pred_df = pd.DataFrame({\"ID\": test[\"ID\"]})\n",
    "\n",
    "for target in target_cols:\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"[FULL AutoML] Running Best Quality AutoML for {target}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # 타깃별 데이터 구성 (ID 제거, X + 해당 Y만 사용)\n",
    "    df_target = train[[\"ID\"] + X_cols + [target]].drop(columns=[\"ID\"])\n",
    "\n",
    "    # FULL AutoML 설정\n",
    "    predictor = TabularPredictor(\n",
    "        label=target,\n",
    "        path=f\"{MODEL_ROOT}/{target}\",\n",
    "        eval_metric=\"root_mean_squared_error\",\n",
    "    )\n",
    "\n",
    "    predictor.fit(\n",
    "        train_data=df_target,\n",
    "        presets=\"best_quality\",\n",
    "        time_limit=300,        # 타깃당 300초 (원하면 더 늘려서 성능↑)\n",
    "        dynamic_stacking=False,\n",
    "        verbosity=2,\n",
    "    )\n",
    "\n",
    "    # Rank / Ensemble 등 포함 전체 모델 리스트\n",
    "    print(predictor.leaderboard(silent=True))\n",
    "\n",
    "    # 테스트 추론\n",
    "    test_X = test[X_cols].copy()\n",
    "    pred = predictor.predict(test_X)\n",
    "\n",
    "    # spec min/max 적용\n",
    "    pred = pred.clip(spec_min[target], spec_max[target])\n",
    "\n",
    "    test_pred_df[target] = pred"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxisOC63ZrNw",
    "outputId": "8a63a6f7-6026-453b-b98e-77dc36d7d315"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_01\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
      "Disk Space Avail:   65.92 GB / 112.64 GB (58.5%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_01\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_01\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_01\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4.409, 0.017, 1.35381, 0.35622)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11129.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.78s of the 74.77s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.353\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 71.51s of the 71.51s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.3541\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 69.36s of the 69.36s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.3543\t = Validation score   (-root_mean_squared_error)\n",
      "\t393.89s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.78s of the -336.71s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.75, 'RandomForestMSE': 0.25}\n",
      "\t-0.3528\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 411.78s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6748.0 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_01\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.352814  root_mean_squared_error       0.370481   \n",
      "1           LightGBMXT  -0.353006  root_mean_squared_error       0.051995   \n",
      "2             LightGBM  -0.354138  root_mean_squared_error       0.013149   \n",
      "3      RandomForestMSE  -0.354314  root_mean_squared_error       0.318036   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  397.087710                0.000451           0.007149            2   \n",
      "1    3.186889                0.051995           3.186889            1   \n",
      "2    2.122100                0.013149           2.122100            1   \n",
      "3  393.893672                0.318036         393.893672            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          1  \n",
      "2       True          2  \n",
      "3       True          3  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_02\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.84 GB / 12.67 GB (85.5%)\n",
      "Disk Space Avail:   65.31 GB / 112.64 GB (58.0%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_02\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_02\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_02\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (3.998, 0.007, 1.05727, 0.38627)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11114.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.78s of the 74.78s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.3834\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.27s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 72.47s of the 72.47s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.3837\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 70.48s of the 70.48s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.3827\t = Validation score   (-root_mean_squared_error)\n",
      "\t395.02s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.78s of the -358.09s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.643, 'LightGBMXT': 0.286, 'LightGBM': 0.071}\n",
      "\t-0.3824\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 433.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6951.4 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_02\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.382360  root_mean_squared_error       0.359638   \n",
      "1      RandomForestMSE  -0.382676  root_mean_squared_error       0.324543   \n",
      "2           LightGBMXT  -0.383446  root_mean_squared_error       0.022727   \n",
      "3             LightGBM  -0.383656  root_mean_squared_error       0.012005   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  399.261153                0.000363           0.007108            2   \n",
      "1  395.017214                0.324543         395.017214            1   \n",
      "2    2.268379                0.022727           2.268379            1   \n",
      "3    1.968452                0.012005           1.968452            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          3  \n",
      "2       True          1  \n",
      "3       True          2  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_03\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.77 GB / 12.67 GB (85.0%)\n",
      "Disk Space Avail:   64.71 GB / 112.64 GB (57.4%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_03\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_03\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_03\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (3.756, 0.017, 1.014, 0.36149)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11048.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.77s of the 74.77s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.3614\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 72.31s of the 72.30s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.3617\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 69.84s of the 69.84s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.3609\t = Validation score   (-root_mean_squared_error)\n",
      "\t390.11s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.77s of the -343.34s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.571, 'LightGBMXT': 0.357, 'LightGBM': 0.071}\n",
      "\t-0.3605\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 418.4s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 7247.6 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_03\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.360489  root_mean_squared_error       0.344943   \n",
      "1      RandomForestMSE  -0.360948  root_mean_squared_error       0.309721   \n",
      "2           LightGBMXT  -0.361397  root_mean_squared_error       0.026056   \n",
      "3             LightGBM  -0.361673  root_mean_squared_error       0.008769   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  394.984637                0.000398           0.007361            2   \n",
      "1  390.109634                0.309721         390.109634            1   \n",
      "2    2.424071                0.026056           2.424071            1   \n",
      "3    2.443571                0.008769           2.443571            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          3  \n",
      "2       True          1  \n",
      "3       True          2  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_04\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.83 GB / 12.67 GB (85.5%)\n",
      "Disk Space Avail:   64.10 GB / 112.64 GB (56.9%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_04\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_04\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_04\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (98.794, -0.331, 13.62119, 2.68663)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11107.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.76s of the 74.76s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\tvalid_set's rmse: 2.60857\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t-2.6065\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.11s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 65.37s of the 65.37s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\tvalid_set's rmse: 2.61992\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t-2.6168\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.33s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 56.81s of the 56.81s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-2.6086\t = Validation score   (-root_mean_squared_error)\n",
      "\t404.29s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.76s of the -386.79s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.409, 'LightGBMXT': 0.364, 'LightGBM': 0.227}\n",
      "\t-2.5947\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 461.86s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4240.3 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_04\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -2.594706  root_mean_squared_error       0.589576   \n",
      "1           LightGBMXT  -2.606472  root_mean_squared_error       0.159016   \n",
      "2      RandomForestMSE  -2.608607  root_mean_squared_error       0.304393   \n",
      "3             LightGBM  -2.616842  root_mean_squared_error       0.125685   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  421.750085                0.000483           0.013398            2   \n",
      "1    9.113374                0.159016           9.113374            1   \n",
      "2  404.293136                0.304393         404.293136            1   \n",
      "3    8.330177                0.125685           8.330177            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          1  \n",
      "2       True          3  \n",
      "3       True          2  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_05\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.81 GB / 12.67 GB (85.3%)\n",
      "Disk Space Avail:   63.49 GB / 112.64 GB (56.4%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_05\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_05\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_05\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (37.25, 18.589, 31.29047, 2.54322)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11086.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.77s of the 74.77s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-2.51\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.72s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 70.94s of the 70.94s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-2.5149\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 68.32s of the 68.32s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-2.5233\t = Validation score   (-root_mean_squared_error)\n",
      "\t433.24s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.77s of the -376.94s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.6, 'LightGBM': 0.24, 'RandomForestMSE': 0.16}\n",
      "\t-2.5081\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 452.02s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5407.8 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_05\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -2.508141  root_mean_squared_error       0.462295   \n",
      "1           LightGBMXT  -2.509992  root_mean_squared_error       0.067295   \n",
      "2             LightGBM  -2.514931  root_mean_squared_error       0.020428   \n",
      "3      RandomForestMSE  -2.523267  root_mean_squared_error       0.374046   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  439.554335                0.000525           0.016737            2   \n",
      "1    3.719975                0.067295           3.719975            1   \n",
      "2    2.581817                0.020428           2.581817            1   \n",
      "3  433.235806                0.374046         433.235806            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          1  \n",
      "2       True          2  \n",
      "3       True          3  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_06\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.80 GB / 12.67 GB (85.3%)\n",
      "Disk Space Avail:   62.89 GB / 112.64 GB (55.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_06\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_06\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_06\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (18.998, -19.963, 16.52938, 1.89301)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11086.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.77s of the 74.77s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\tvalid_set's rmse: 2.21202\n",
      "[2000]\tvalid_set's rmse: 2.20202\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t-2.2\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.09s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 62.28s of the 62.28s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-2.1561\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.1s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 58.09s of the 58.09s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-2.2504\t = Validation score   (-root_mean_squared_error)\n",
      "\t473.39s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.77s of the -428.77s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.96, 'LightGBMXT': 0.04}\n",
      "\t-2.1561\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 503.84s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9675.5 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_06\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -2.156094  root_mean_squared_error       0.258384   \n",
      "1             LightGBM  -2.156133  root_mean_squared_error       0.039498   \n",
      "2           LightGBMXT  -2.199963  root_mean_squared_error       0.218541   \n",
      "3      RandomForestMSE  -2.250411  root_mean_squared_error       0.318135   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   16.197848                0.000345           0.007009            2   \n",
      "1    4.103916                0.039498           4.103916            1   \n",
      "2   12.086923                0.218541          12.086923            1   \n",
      "3  473.389089                0.318135         473.389089            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          2  \n",
      "2       True          1  \n",
      "3       True          3  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_07\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
      "Disk Space Avail:   62.28 GB / 112.64 GB (55.3%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_07\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_07\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_07\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5.299, 0.502, 3.15505, 0.41894)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11127.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.70s of the 74.69s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.4178\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.0s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 68.57s of the 68.57s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.417\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 63.64s of the 63.64s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.4181\t = Validation score   (-root_mean_squared_error)\n",
      "\t414.59s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.70s of the -399.34s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.5, 'RandomForestMSE': 0.286, 'LightGBMXT': 0.214}\n",
      "\t-0.4161\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 474.54s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3873.0 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_07\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.416119  root_mean_squared_error       0.645487   \n",
      "1             LightGBM  -0.416989  root_mean_squared_error       0.043071   \n",
      "2           LightGBMXT  -0.417799  root_mean_squared_error       0.061880   \n",
      "3      RandomForestMSE  -0.418086  root_mean_squared_error       0.540041   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  425.414660                0.000495           0.007882            2   \n",
      "1    4.818474                0.043071           4.818474            1   \n",
      "2    6.000837                0.061880           6.000837            1   \n",
      "3  414.587467                0.540041         414.587467            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          2  \n",
      "2       True          1  \n",
      "3       True          3  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_08\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.85 GB / 12.67 GB (85.6%)\n",
      "Disk Space Avail:   61.67 GB / 112.64 GB (54.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_08\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_08\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_08\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (-23.785, -29.652, -26.29484, 0.66054)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11129.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.75s of the 74.75s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.6459\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.35s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 69.27s of the 69.26s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.6437\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 65.95s of the 65.95s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.6409\t = Validation score   (-root_mean_squared_error)\n",
      "\t413.39s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.75s of the -402.27s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.692, 'LightGBM': 0.308}\n",
      "\t-0.6402\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 477.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 7433.6 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_08\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.640174  root_mean_squared_error       0.336310   \n",
      "1      RandomForestMSE  -0.640868  root_mean_squared_error       0.309373   \n",
      "2             LightGBM  -0.643661  root_mean_squared_error       0.026596   \n",
      "3           LightGBMXT  -0.645887  root_mean_squared_error       0.076383   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  416.664715                0.000341           0.006924            2   \n",
      "1  413.393259                0.309373         413.393259            1   \n",
      "2    3.264532                0.026596           3.264532            1   \n",
      "3    5.348052                0.076383           5.348052            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          3  \n",
      "2       True          2  \n",
      "3       True          1  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_09\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.82 GB / 12.67 GB (85.4%)\n",
      "Disk Space Avail:   61.06 GB / 112.64 GB (54.2%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_09\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_09\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_09\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (-23.96, -29.523, -26.30862, 0.65358)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11103.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.74s of the 74.74s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.6444\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.06s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 70.56s of the 70.56s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.6432\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 66.09s of the 66.08s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.6396\t = Validation score   (-root_mean_squared_error)\n",
      "\t409.73s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.74s of the -364.03s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.7, 'LightGBM': 0.3}\n",
      "\t-0.6388\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 439.1s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 7309.8 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_09\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.638795  root_mean_squared_error       0.342006   \n",
      "1      RandomForestMSE  -0.639556  root_mean_squared_error       0.304865   \n",
      "2             LightGBM  -0.643161  root_mean_squared_error       0.036704   \n",
      "3           LightGBMXT  -0.644439  root_mean_squared_error       0.077878   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  414.125468                0.000437           0.009432            2   \n",
      "1  409.732295                0.304865         409.732295            1   \n",
      "2    4.383742                0.036704           4.383742            1   \n",
      "3    4.055288                0.077878           4.055288            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          3  \n",
      "2       True          2  \n",
      "3       True          1  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_10\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.82 GB / 12.67 GB (85.4%)\n",
      "Disk Space Avail:   60.46 GB / 112.64 GB (53.7%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_10\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_10\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_10\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (-20.052, -31.119, -22.40006, 0.92095)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11102.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.74s of the 74.74s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\tvalid_set's rmse: 0.925846\n",
      "[2000]\tvalid_set's rmse: 0.924569\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t-0.9237\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.44s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 58.77s of the 58.77s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.9095\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.23s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 53.44s of the 53.44s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.9211\t = Validation score   (-root_mean_squared_error)\n",
      "\t412.44s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.74s of the -367.08s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.792, 'RandomForestMSE': 0.125, 'LightGBMXT': 0.083}\n",
      "\t-0.9091\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 442.15s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3821.2 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_10\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.909071  root_mean_squared_error       0.654251   \n",
      "1             LightGBM  -0.909485  root_mean_squared_error       0.042009   \n",
      "2      RandomForestMSE  -0.921108  root_mean_squared_error       0.305050   \n",
      "3           LightGBMXT  -0.923692  root_mean_squared_error       0.306829   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  433.113649                0.000362           0.006954            2   \n",
      "1    5.230775                0.042009           5.230775            1   \n",
      "2  412.440796                0.305050         412.440796            1   \n",
      "3   15.435124                0.306829          15.435124            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          2  \n",
      "2       True          3  \n",
      "3       True          1  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_11\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.83 GB / 12.67 GB (85.5%)\n",
      "Disk Space Avail:   59.84 GB / 112.64 GB (53.1%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_11\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_11\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_11\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (26.703, 19.844, 24.32506, 0.8302)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11100.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.75s of the 74.74s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.8346\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 69.56s of the 69.56s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.8345\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 66.13s of the 66.13s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.8369\t = Validation score   (-root_mean_squared_error)\n",
      "\t434.27s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.75s of the -414.35s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.4, 'LightGBMXT': 0.333, 'RandomForestMSE': 0.267}\n",
      "\t-0.8327\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 489.42s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6299.1 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_11\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.832702  root_mean_squared_error       0.396882   \n",
      "1             LightGBM  -0.834539  root_mean_squared_error       0.027861   \n",
      "2           LightGBMXT  -0.834626  root_mean_squared_error       0.053039   \n",
      "3      RandomForestMSE  -0.836941  root_mean_squared_error       0.315641   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  442.718341                0.000340           0.007228            2   \n",
      "1    3.375629                0.027861           3.375629            1   \n",
      "2    5.069798                0.053039           5.069798            1   \n",
      "3  434.265686                0.315641         434.265686            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          2  \n",
      "2       True          1  \n",
      "3       True          3  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_12\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.82 GB / 12.67 GB (85.4%)\n",
      "Disk Space Avail:   59.24 GB / 112.64 GB (52.6%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_12\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_12\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_12\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (-23.722, -29.544, -26.23776, 0.65633)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11101.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.70s of the 74.70s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\tvalid_set's rmse: 0.641582\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t-0.6415\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.18s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 66.27s of the 66.27s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1000]\tvalid_set's rmse: 0.639965\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\t-0.6392\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.17s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 58.76s of the 58.76s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.6408\t = Validation score   (-root_mean_squared_error)\n",
      "\t423.89s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.70s of the -408.90s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.5, 'RandomForestMSE': 0.357, 'LightGBMXT': 0.143}\n",
      "\t-0.6371\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 483.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4064.7 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_12\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.637081  root_mean_squared_error       0.615051   \n",
      "1             LightGBM  -0.639243  root_mean_squared_error       0.156700   \n",
      "2      RandomForestMSE  -0.640819  root_mean_squared_error       0.312625   \n",
      "3           LightGBMXT  -0.641537  root_mean_squared_error       0.145287   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  439.241251                0.000438           0.006988            2   \n",
      "1    7.167267                0.156700           7.167267            1   \n",
      "2  423.890227                0.312625         423.890227            1   \n",
      "3    8.176769                0.145287           8.176769            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          2  \n",
      "2       True          3  \n",
      "3       True          1  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_13\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.81 GB / 12.67 GB (85.3%)\n",
      "Disk Space Avail:   58.63 GB / 112.64 GB (52.1%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_13\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_13\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_13\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (-23.899, -29.448, -26.23387, 0.65509)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11109.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.2s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.74s of the 74.74s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.646\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.93s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 70.70s of the 70.70s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.6451\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 66.07s of the 66.07s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.6409\t = Validation score   (-root_mean_squared_error)\n",
      "\t421.05s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.74s of the -407.81s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.778, 'LightGBM': 0.222}\n",
      "\t-0.6405\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 482.87s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6884.9 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_13\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.640473  root_mean_squared_error       0.363112   \n",
      "1      RandomForestMSE  -0.640858  root_mean_squared_error       0.330220   \n",
      "2             LightGBM  -0.645058  root_mean_squared_error       0.032512   \n",
      "3           LightGBMXT  -0.645978  root_mean_squared_error       0.052876   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  425.608009                0.000380           0.007964            2   \n",
      "1  421.049791                0.330220         421.049791            1   \n",
      "2    4.550253                0.032512           4.550253            1   \n",
      "3    3.928157                0.052876           3.928157            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          3  \n",
      "2       True          2  \n",
      "3       True          1  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autonomous_driving/Autogluon_Full/Y_14\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
      "CPU Count:          2\n",
      "Memory Avail:       10.82 GB / 12.67 GB (85.4%)\n",
      "Disk Space Avail:   58.02 GB / 112.64 GB (51.5%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "[FULL AutoML] Running Best Quality AutoML for Y_14\n",
      "======================================================================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Beginning AutoGluon training ... Time limit = 75s\n",
      "AutoGluon will save models to \"/content/autonomous_driving/Autogluon_Full/Y_14\"\n",
      "Train Data Rows:    39607\n",
      "Train Data Columns: 56\n",
      "Label Column:       Y_14\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (-23.856, -29.62, -26.24587, 0.65599)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11122.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.92 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['X_04', 'X_23', 'X_47', 'X_48']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 51 | ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', ...]\n",
      "\t\t('int', [])   :  1 | ['X_46']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['X_01', 'X_03', 'X_05', 'X_06', 'X_07', ...]\n",
      "\t\t('int', [])       :  1 | ['X_46']\n",
      "\t\t('int', ['bool']) :  1 | ['X_02']\n",
      "\t0.3s = Fit runtime\n",
      "\t52 features in original data used to generate 52 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 15.45 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06312015552806322, Train Rows: 37107, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 74.64s of the 74.64s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.6421\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.62s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 70.96s of the 70.96s of remaining time.\n",
      "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
      "\t-0.64\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 66.71s of the 66.70s of remaining time.\n",
      "\tFitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
      "\t-0.6396\t = Validation score   (-root_mean_squared_error)\n",
      "\t411.89s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 74.64s of the -373.60s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.533, 'LightGBM': 0.467}\n",
      "\t-0.6379\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 448.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 6873.7 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/autonomous_driving/Autogluon_Full/Y_14\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 model  score_val              eval_metric  pred_time_val  \\\n",
      "0  WeightedEnsemble_L2  -0.637878  root_mean_squared_error       0.363703   \n",
      "1      RandomForestMSE  -0.639629  root_mean_squared_error       0.322094   \n",
      "2             LightGBM  -0.640033  root_mean_squared_error       0.041187   \n",
      "3           LightGBMXT  -0.642097  root_mean_squared_error       0.035200   \n",
      "\n",
      "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0  416.055759                0.000422           0.008759            2   \n",
      "1  411.891634                0.322094         411.891634            1   \n",
      "2    4.155366                0.041187           4.155366            1   \n",
      "3    3.624561                0.035200           3.624561            1   \n",
      "\n",
      "   can_infer  fit_order  \n",
      "0       True          4  \n",
      "1       True          3  \n",
      "2       True          2  \n",
      "3       True          1  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# 4. 제출 파일 생성\n",
    "# ============================================================\n",
    "\n",
    "submission = sample_submission.copy()\n",
    "for target in target_cols:\n",
    "    submission[target] = test_pred_df[target]\n",
    "\n",
    "SAVE_PATH = f\"{BASE_PATH}/submission_full_automl.csv\"\n",
    "submission.to_csv(SAVE_PATH, index=False)\n",
    "print(\"저장 완료:\", SAVE_PATH)\n",
    "\n",
    "submission.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "16h64C1JaGeI",
    "outputId": "dc41ac51-734e-46b2-f5ad-e7472287559d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "저장 완료: /content/autonomous_driving/submission_full_automl.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           ID      Y_01      Y_02      Y_03       Y_04       Y_05       Y_06  \\\n",
       "0  TEST_00001  1.439908  1.236950  1.162477  14.398384  31.193666  16.900709   \n",
       "1  TEST_00002  1.468054  1.237716  1.149987  13.354094  30.929266  16.676746   \n",
       "2  TEST_00003  1.433068  1.150542  1.093521  14.753347  32.294514  16.803112   \n",
       "3  TEST_00004  1.456332  1.131239  1.019629  15.027258  32.429302  16.919838   \n",
       "4  TEST_00005  1.343061  1.037863  0.983201  15.131520  31.608019  16.769739   \n",
       "\n",
       "       Y_07       Y_08       Y_09       Y_10       Y_11       Y_12       Y_13  \\\n",
       "0  3.092302 -26.101877 -26.115559 -22.182226  24.515551 -25.953695 -26.054943   \n",
       "1  3.192359 -26.279535 -26.204777 -22.283594  24.381147 -26.140133 -26.146376   \n",
       "2  3.089966 -26.025328 -25.969843 -22.274431  24.396717 -25.969030 -25.931866   \n",
       "3  3.105817 -25.742821 -25.776024 -21.763435  24.826448 -25.659613 -25.650757   \n",
       "4  3.082567 -25.705357 -25.652958 -21.947803  24.855724 -25.599371 -25.611864   \n",
       "\n",
       "        Y_14  \n",
       "0 -26.003893  \n",
       "1 -26.126022  \n",
       "2 -25.965626  \n",
       "3 -25.701033  \n",
       "4 -25.651512  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-277f6d25-dc7c-42a7-9f1b-982e64e89d3e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_01</th>\n",
       "      <th>Y_02</th>\n",
       "      <th>Y_03</th>\n",
       "      <th>Y_04</th>\n",
       "      <th>Y_05</th>\n",
       "      <th>Y_06</th>\n",
       "      <th>Y_07</th>\n",
       "      <th>Y_08</th>\n",
       "      <th>Y_09</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_11</th>\n",
       "      <th>Y_12</th>\n",
       "      <th>Y_13</th>\n",
       "      <th>Y_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>1.439908</td>\n",
       "      <td>1.236950</td>\n",
       "      <td>1.162477</td>\n",
       "      <td>14.398384</td>\n",
       "      <td>31.193666</td>\n",
       "      <td>16.900709</td>\n",
       "      <td>3.092302</td>\n",
       "      <td>-26.101877</td>\n",
       "      <td>-26.115559</td>\n",
       "      <td>-22.182226</td>\n",
       "      <td>24.515551</td>\n",
       "      <td>-25.953695</td>\n",
       "      <td>-26.054943</td>\n",
       "      <td>-26.003893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>1.468054</td>\n",
       "      <td>1.237716</td>\n",
       "      <td>1.149987</td>\n",
       "      <td>13.354094</td>\n",
       "      <td>30.929266</td>\n",
       "      <td>16.676746</td>\n",
       "      <td>3.192359</td>\n",
       "      <td>-26.279535</td>\n",
       "      <td>-26.204777</td>\n",
       "      <td>-22.283594</td>\n",
       "      <td>24.381147</td>\n",
       "      <td>-26.140133</td>\n",
       "      <td>-26.146376</td>\n",
       "      <td>-26.126022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>1.433068</td>\n",
       "      <td>1.150542</td>\n",
       "      <td>1.093521</td>\n",
       "      <td>14.753347</td>\n",
       "      <td>32.294514</td>\n",
       "      <td>16.803112</td>\n",
       "      <td>3.089966</td>\n",
       "      <td>-26.025328</td>\n",
       "      <td>-25.969843</td>\n",
       "      <td>-22.274431</td>\n",
       "      <td>24.396717</td>\n",
       "      <td>-25.969030</td>\n",
       "      <td>-25.931866</td>\n",
       "      <td>-25.965626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>1.456332</td>\n",
       "      <td>1.131239</td>\n",
       "      <td>1.019629</td>\n",
       "      <td>15.027258</td>\n",
       "      <td>32.429302</td>\n",
       "      <td>16.919838</td>\n",
       "      <td>3.105817</td>\n",
       "      <td>-25.742821</td>\n",
       "      <td>-25.776024</td>\n",
       "      <td>-21.763435</td>\n",
       "      <td>24.826448</td>\n",
       "      <td>-25.659613</td>\n",
       "      <td>-25.650757</td>\n",
       "      <td>-25.701033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00005</td>\n",
       "      <td>1.343061</td>\n",
       "      <td>1.037863</td>\n",
       "      <td>0.983201</td>\n",
       "      <td>15.131520</td>\n",
       "      <td>31.608019</td>\n",
       "      <td>16.769739</td>\n",
       "      <td>3.082567</td>\n",
       "      <td>-25.705357</td>\n",
       "      <td>-25.652958</td>\n",
       "      <td>-21.947803</td>\n",
       "      <td>24.855724</td>\n",
       "      <td>-25.599371</td>\n",
       "      <td>-25.611864</td>\n",
       "      <td>-25.651512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-277f6d25-dc7c-42a7-9f1b-982e64e89d3e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-277f6d25-dc7c-42a7-9f1b-982e64e89d3e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-277f6d25-dc7c-42a7-9f1b-982e64e89d3e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-3076ab81-801b-4ee9-8401-db211a152826\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3076ab81-801b-4ee9-8401-db211a152826')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-3076ab81-801b-4ee9-8401-db211a152826 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "submission",
       "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 39608,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39608,\n        \"samples\": [\n          \"TEST_17964\",\n          \"TEST_14238\",\n          \"TEST_02993\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_01\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 39261,\n        \"samples\": [\n          1.4140625,\n          1.446049690246582,\n          1.3623812198638916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_02\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 39316,\n        \"samples\": [\n          0.9753079414367676,\n          1.044355869293213,\n          1.1780668497085571\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_03\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 39280,\n        \"samples\": [\n          1.0119152069091797,\n          1.0396157503128052,\n          1.0705626010894775\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_04\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 39281,\n        \"samples\": [\n          13.843450546264648,\n          12.72962760925293,\n          13.987897872924805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_05\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 38698,\n        \"samples\": [\n          31.398881912231445,\n          32.04121398925781,\n          30.864458084106445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_06\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37493,\n        \"samples\": [\n          16.431486129760742,\n          15.99804401397705,\n          16.596372604370117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_07\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 38969,\n        \"samples\": [\n          3.2084367275238037,\n          3.3104591369628906,\n          3.0338056087493896\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_08\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37481,\n        \"samples\": [\n          -26.781845092773438,\n          -26.208250045776367,\n          -26.529306411743164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_09\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37253,\n        \"samples\": [\n          -26.49350357055664,\n          -26.231922149658203,\n          -26.010997772216797\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_10\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 38015,\n        \"samples\": [\n          -22.601346969604492,\n          -22.438655853271484,\n          -22.526113510131836\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_11\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 36924,\n        \"samples\": [\n          24.338621139526367,\n          24.18329620361328,\n          24.233882904052734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_12\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37463,\n        \"samples\": [\n          -26.261995315551758,\n          -25.99162483215332,\n          -26.071306228637695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_13\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37348,\n        \"samples\": [\n          -26.049943923950195,\n          -25.943614959716797,\n          -26.537662506103516\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y_14\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 37407,\n        \"samples\": [\n          -26.351734161376953,\n          -26.16039276123047,\n          -26.205995559692383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Oj_2R-JJargK"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}